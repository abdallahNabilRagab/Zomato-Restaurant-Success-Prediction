# ğŸ½ï¸ Zomato Restaurant Success Prediction  
A Complete End-to-End Machine Learning Pipeline  
Built by **Abdallah Nabil Ragab**

---

## ğŸ“Š Project Overview

This project predicts whether a restaurant listed in the **Zomato Bangalore Dataset** will be **successful** based on multiple business, operational, and customer-related features.

A full **MLOps-ready pipeline** was implemented:

- Data ingestion & deep cleaning  
- Business rule validation  
- Feature engineering  
- Train/test preparation  
- Model training (5 ML algorithms)  
- Hyperparameter tuning  
- Model selection  
- Production-grade inference  
- Streamlit app for deployment  

Dataset Source (Kaggle):  
Zomato Bangalore Restaurants Dataset  
(Contains 9,000+ restaurants with 21+ features)

---

## ğŸ“‚ Project Structure

```
project_structure/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py              # Streamlit prediction app
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Original raw data
â”‚   â”œâ”€â”€ preprocessed/                 # Cleaned & engineered datasets
â”‚   â””â”€â”€ processed/                    # Model-ready datasets
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ saved_models/                 # Optimized ML models (pickle)
â”‚   â”œâ”€â”€ scalers/                      # Saved transformers
â”‚   â””â”€â”€ encoders/                     # Saved encoders
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ data_pipeline.py              # Data cleaning + EDA + feature engineering
    â”œâ”€â”€ inference.py                  # Production inference pipeline
    â”œâ”€â”€ model.py                      # Model factory (all ML algorithms)
    â”œâ”€â”€ train.py                      # Training + model evaluation
    â”œâ”€â”€ utils.py                      # Utilities & shared helpers
    â””â”€â”€ __init__.py
```

---

# ğŸ“ Dataset Description

**Source:** [Zomato Dataset on Kaggle](https://www.kaggle.com/datasets/rajeshrampure/zomato-dataset/data)  

The Zomato dataset contains restaurant information such as:

| Column | Description |
|--------|-------------|
| `name` | Restaurant name |
| `location` | Area / district |
| `listed_in(type)` | Dining / CafÃ©s / Quick Bites / etc. |
| `listed_in(city)` | City group |
| `cuisines` | Type of cuisines served |
| `rest_type` | Restaurant business type |
| `approx_cost(for two people)` | Cost estimate |
| `online_order` | Accepts online orders? |
| `book_table` | Table reservation available? |
| `rate` | Customer rating |
| `votes` | Number of votes |
| `phone`, `menu_item` | Optional business fields |

### ğŸ§ª Target Variable  
A success label was engineered:

- **1** â†’ Rating â‰¥ 3.75  
- **0** â†’ Otherwise

---

# ğŸ”§ Module-by-Module Documentation

---

# ğŸ“Œ `src/data_pipeline.py` â€” *Full Data Processing Pipeline*

A production-ready data preparation pipeline performing:

### âœ” 1. Data Loading & Basic Cleaning
- Remove irrelevant columns  
- Normalize rating values (`4.2/5`, `NEW`, `-`)  
- Convert `votes` to numeric  
- Fix cost values with commas (`1,200` â†’ `1200`)  
- Clean text fields (cuisines, rest_type, location)

### âœ” 2. Business Rule Validation
- Remove rows with invalid cuisine/rest types  
- Validate consistency between `location` and `listed_city`

### âœ” 3. Feature Engineering
- Target creation  
- Cuisine grouping into â€œregional familiesâ€  
- Cost/rating/votes binning  
- Operational classification for restaurant types  
- Binary transformations for online/table/menu features  

### âœ” 4. Data Validation
- Missing value detection  
- Duplicates check  
- Target imbalance reporting  

### âœ” 5. Optional EDA
Automatically generates:
- Univariate plots  
- Correlation heatmaps  
- Target-related behaviour  

### âœ” 6. Saving Output
- Writes processed dataset to `data/preprocessed/`  
- Splits into **Train** / **Test** using timestamp naming  

### â–¶ Example
```python
from src.data_pipeline import run_pipeline

run_pipeline(
    raw_path="data/raw/zomato.csv",
    save_path="data/preprocessed/zomato_cleaned.csv",
    training=True,
    run_eda=True,
    split_data=True
)
```

---

# ğŸ¤– `src/model.py` â€” *Model Factory*

A clean factory to generate ML models with optimized hyperparameters.

Supported algorithms:

| Model | Purpose |
|--------|----------|
| Logistic Regression | Lightweight baseline |
| Linear SVM | Strong linear classifier |
| Decision Tree | Rules & interpretability |
| Random Forest | Ensemble-based robustness |
| XGBoost | Best performer for structured data |

### Example:
```python
from src.model import get_xgb_classifier
model = get_xgb_classifier()
```

---

# ğŸ‹ï¸â€â™‚ï¸ `src/train.py` â€” *Automated Training Pipeline*

Handles all training steps:

### âœ” Load latest preprocessed data  
### âœ” Preprocess using:
- RobustScaler  
- BinaryEncoder  
- ColumnTransformer pipeline  

### âœ” Train 5 ML models using `GridSearchCV`  
### âœ” Evaluate performance  
### âœ” Save:
- Processor (scaler + encoder)
- Best model for each algorithm  
- All in timestamped folders

### â–¶ Run training:
```bash
python src/train.py
```

---

# ğŸš€ `src/inference.py` â€” *Production Inference*

Automatically:

1. Loads latest test file  
2. Loads saved processor  
3. Loads all trained models  
4. Predicts & evaluates  
5. Computes metrics:

- Accuracy  
- Precision/Recall/F1  
- ROC-AUC  
- PR-AUC  
- MCC  
- Confusion Matrix  

### â–¶ Run inference:
```bash
python src/inference.py
```

---

# ğŸ–¥ï¸ `app/streamlit_app.py` â€” *Interactive Prediction App*

A powerful UI to test models in real time.

### Features:
âœ” Upload or auto-load processor & model  
âœ” User input form (city, cost, cuisines, votes, etc.)  
âœ” Transforms data exactly like training  
âœ” Predicts restaurant success  
âœ” Displays probabilities  
âœ” Debugging mode for developers  

### â–¶ Run Streamlit:
```bash
cd app
streamlit run streamlit_app.py
```

---

# ğŸ§° Utility Functions (`utils.py`)

- File search helpers  
- Timestamp utilities  
- Safe loading wrappers  
- Pretty model naming  
- Logging helpers  

---

# âš™ï¸ How to Run the Whole Project

### 1. Place raw dataset:
```
data/raw/zomato.csv
```

### 2. Run preprocessing:
```bash
python src/data_pipeline.py
```

### 3. Train models:
```bash
python src/train.py
```

### 4. Run inference:
```bash
python src/inference.py
```

### 5. Launch Streamlit:
```bash
streamlit run app/streamlit_app.py
```

---

# ğŸ‘¨â€ğŸ’» **Developer Information**

**Name:** *Abdallah Nabil Ragab*  
**Role:** Data Scientist â€¢ ML Engineer â€¢ Software Engineer  
**M.Sc. â€” Business Information Systems**  
**Email:** abdallah.nabil.ragab94@gmail.com  

ğŸ”¬ Specializes in:  
- Machine Learning & AI  
- Large-scale Recommendation Systems  
- Data Pipelines & MLOps  
- Python software engineering  
- Streamlit apps  
- NLP & classification systems  

ğŸ“Œ *Feedback, collaboration, and feature requests are always welcome.*

---

# â­ Summary

This repository provides a completely automated machine learning system:

- Raw â†’ Clean â†’ Features â†’ Train â†’ Evaluate â†’ Inference â†’ Streamlit UI  
- Supports 5 ML models  
- Uses timestamped versioning  
- Production-ready and fully modular  
- Clear pipeline structure for reproducibility  

A powerful, scalable solution for real-world restaurant success prediction ğŸš€

